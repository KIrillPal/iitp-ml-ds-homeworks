{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "source": [
    "# Parameter search comparisons\n",
    "\n",
    "1. GridSearch\n",
    "2. RandomSearch\n",
    "3. HyperOpt Usage\n",
    "\n",
    "> We will use IDAO-2020 data for demonstration.\n",
    "https://www.kaggle.com/datasets/neibyr/idao2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a5d7f0be2e15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCatBoostRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to create the collection: Prompt dismissed..\u001b[0m\n",
      "Collecting catboost\n",
      "  Downloading catboost-1.0.4-cp38-none-manylinux1_x86_64.whl (76.1 MB)\n",
      "\u001b[K     |██████▋                         | 15.7 MB 141 kB/s eta 0:07:07"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED=5\n",
    "\n",
    "train = pd.read_csv('../input/idao2020/data/train.csv', index_col=0)\n",
    "test =  pd.read_csv('../input/idao2020/data/Track 1/test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(df):\n",
    "    '''minimal preprocessing'''\n",
    "    date = pd.to_datetime(df.epoch)\n",
    "    # year and month are the same accross the data\n",
    "    df['day'] = date.dt.day\n",
    "    df['weekday'] = date.dt.weekday\n",
    "    df['hour'] = date.dt.hour\n",
    "    df['minute'] = date.dt.minute\n",
    "    df['second'] = date.dt.second\n",
    "    \n",
    "    return df.drop('epoch', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = prepare_features(train)\n",
    "X = train[['x_sim', 'y_sim', 'z_sim',\n",
    "           'Vx_sim', 'Vy_sim', 'Vz_sim',\n",
    "           'sat_id', 'day', 'weekday', 'hour', 'minute','second']]\n",
    "Y = train[['x', 'y', 'z',\n",
    "           'Vx', 'Vy', 'Vz']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sattelite based cross-validation\n",
    "\n",
    "rgn = RandomForestRegressor(n_estimators=10)\n",
    "cv = list(KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED).split(X, Y['x'], groups=X['sat_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': np.arange(3,8,2),\n",
    "    'min_samples_split': np.arange(2,25,5),\n",
    "    'min_samples_leaf': [5],\n",
    "    'max_features': [0.3, 0.7],\n",
    "    'random_state':[RANDOM_SEED],\n",
    "}\n",
    "gs = GridSearchCV(estimator=rgn,\n",
    "                  param_grid=params,\n",
    "                  scoring='neg_mean_squared_error',\n",
    "                  cv=cv,\n",
    "                  n_jobs=10,\n",
    "                  verbose=5,\n",
    "                  iid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(X, Y['x'])\n",
    "# ~10 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': stats.randint(2, 8),\n",
    "    'min_samples_split': stats.randint(2, 25),\n",
    "    'min_samples_leaf': [5],\n",
    "    'max_features': stats.uniform(),\n",
    "    'random_state':[RANDOM_SEED],\n",
    "}\n",
    "\n",
    "\n",
    "rs = RandomizedSearchCV(estimator=rgn,\n",
    "                       param_distributions=params,\n",
    "                       n_iter=30,\n",
    "                       scoring='neg_mean_squared_error',\n",
    "                       n_jobs=10,\n",
    "                       cv=cv,\n",
    "                       verbose=5,\n",
    "                       random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.fit(X, Y['x'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Hyperopt usage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import Trials, fmin, hp, tpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgn = RandomForestRegressor(n_estimators=10, min_samples_leaf=5, random_state=RANDOM_SEED)\n",
    "\n",
    "def score(params):\n",
    "    print(f\"Training with params: {params}\")\n",
    "    rgn.set_params(**params)\n",
    "    cv = list(KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED).split(X, Y['x'], groups=X['sat_id']))\n",
    "    neg_mse = cross_val_score(rgn, X, Y['x'], scoring='neg_mean_squared_error', cv=cv).mean()        \n",
    "    return -neg_mse\n",
    "\n",
    "\n",
    "def optimize(random_state=RANDOM_SEED, niter=2):\n",
    "    param_space = {\n",
    "    'max_depth': hp.choice('max_depth', np.arange(2, 8, dtype=int)),\n",
    "    'min_samples_split': hp.choice('min_samples_split', np.arange(2, 25, dtype=int)),\n",
    "    'max_features': hp.uniform('max_features',0, 1.),\n",
    "    }\n",
    "    trials = Trials()\n",
    "    best = fmin(score, param_space, algo=tpe.suggest, \n",
    "                trials=trials, \n",
    "                max_evals=niter,\n",
    "                rstate=np.random.RandomState(random_state)\n",
    "               )\n",
    "    return best, trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use niter=2 for minimal example\n",
    "best_hyperparams, trials = optimize(niter=30) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperOpt `fmin` returns indexes for `choice` defined parameters \n",
    "\n",
    "np.arange(2, 8, dtype=int)[5], np.arange(2, 25, dtype=int)[1]\n",
    "\n",
    "best_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkout trials object\n",
    "\n",
    "print(trials.results)\n",
    "print(trials.best_trial)\n",
    "print(trials.idxs_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgn = RandomForestRegressor(n_estimators=10, min_samples_leaf=5, random_state=RANDOM_SEED, n_jobs=-1)\n",
    "rgn.set_params(**gs.best_params_)\n",
    "cross_val_score(rgn, X, Y['x'], cv=cv, scoring='neg_mean_squared_error').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgn = RandomForestRegressor(n_estimators=10, min_samples_leaf=5, random_state=RANDOM_SEED, n_jobs=-1)\n",
    "rgn.set_params(**rs.best_params_)\n",
    "cross_val_score(rgn, X, Y['x'], cv=cv, scoring='neg_mean_squared_error').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'max_depth': 5, 'max_features': 0.9336701952987806, 'min_samples_split': 1}\n",
    "\n",
    "rgn = RandomForestRegressor(n_estimators=10, min_samples_leaf=5, max_features=0.9336701952987806,\n",
    "                            min_samples_split = 3, max_depth=7,\n",
    "                            random_state=RANDOM_SEED, n_jobs=-1)\n",
    "cross_val_score(rgn, X, Y['x'], cv=cv, scoring='neg_mean_squared_error').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
